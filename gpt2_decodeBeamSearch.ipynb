{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "[Paper on CAUSAL Transformer](https://arxiv.org/pdf/2106.01345)\n",
    "\n",
    "FAQ\n",
    "\n",
    "[HUGGING FACE RL WITH DL](https://huggingface.co/learn/deep-rl-course/en/unitbonus3/curriculum-learning)\n",
    "\n",
    "[Ref Notebook on Google](https://colab.research.google.com/drive/1ezT24sogpVyr2HJLOvXHzjv61JZJ1gMT?usp=sharing#scrollTo=0MJJZEylVO-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "data = load_dataset('li2017dailydialog/daily_dialog')\n",
    "\n",
    "df = data['train'].to_pandas().head(1000)\n",
    "df['dial_id'] = df.index.values\n",
    "dfs = df.explode(['dialog', 'act', 'emotion'], ignore_index=True)\n",
    "dfs['response'] = dfs.groupby('dial_id')['dialog'].shift(-1)\n",
    "dfs['response_emote'] = dfs.groupby('dial_id')['emotion'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "      <th>act</th>\n",
       "      <th>emotion</th>\n",
       "      <th>dial_id</th>\n",
       "      <th>response</th>\n",
       "      <th>response_emote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You know that is tempting but is really not g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You know that is tempting but is really not g...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you mean ? It will help us to relax .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you mean ? It will help us to relax .</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you really think so ? I don't . It will ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you really think so ? I don't . It will ju...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I guess you are right.But what shall we do ? ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I guess you are right.But what shall we do ? ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I suggest a walk over to the gym where we can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>How about this sunday ?</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>Ok , cool .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>Ok , cool .</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>Good . I'll give you a call tonight .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7376</th>\n",
       "      <td>Good . I'll give you a call tonight .</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>No problem .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7377</th>\n",
       "      <td>No problem .</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>Bye .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>Bye .</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7379 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 dialog act emotion  dial_id  \\\n",
       "0     Say , Jim , how about going for a few beers af...   3       0        0   \n",
       "1      You know that is tempting but is really not g...   4       0        0   \n",
       "2        What do you mean ? It will help us to relax .    2       0        0   \n",
       "3      Do you really think so ? I don't . It will ju...   2       0        0   \n",
       "4      I guess you are right.But what shall we do ? ...   2       0        0   \n",
       "...                                                 ...  ..     ...      ...   \n",
       "7374                           How about this sunday ?    3       4      999   \n",
       "7375                                       Ok , cool .    4       4      999   \n",
       "7376             Good . I'll give you a call tonight .    1       4      999   \n",
       "7377                                      No problem .    1       4      999   \n",
       "7378                                             Bye .    1       4      999   \n",
       "\n",
       "                                               response response_emote  \n",
       "0      You know that is tempting but is really not g...              0  \n",
       "1        What do you mean ? It will help us to relax .               0  \n",
       "2      Do you really think so ? I don't . It will ju...              0  \n",
       "3      I guess you are right.But what shall we do ? ...              0  \n",
       "4      I suggest a walk over to the gym where we can...              0  \n",
       "...                                                 ...            ...  \n",
       "7374                                       Ok , cool .               4  \n",
       "7375             Good . I'll give you a call tonight .               4  \n",
       "7376                                      No problem .               4  \n",
       "7377                                             Bye .               4  \n",
       "7378                                                NaN            NaN  \n",
       "\n",
       "[7379 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 using AutoModel loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"eos_token_id\": 50256\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,\n",
       " {'input_ids': tensor([[12982,    25, 17207,   703,   389,   345,    30,   220,   198, 36772,\n",
       "             25]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"User: hey how are you? \\nAgent:\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.to('mps')\n",
    "attn_ids = inputs.attention_mask.to('mps')\n",
    "input_length = input_ids.size(1)\n",
    "\n",
    "input_length, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BeamSearchScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search beam params\n",
    "num_beams = 3 # how many beams to trak during the viterbi algorithm \n",
    "num_return_beams = 3 # what is returned after algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a BeamSearchScorer\n",
    "beam_scorer = BeamSearchScorer(\n",
    "    batch_size = input_length,\n",
    "    num_beams = num_beams,\n",
    "    num_beam_hyps_to_keep = num_return_beams,\n",
    "    length_penalty=1, \n",
    "    do_early_stopping=True, \n",
    "    device=model.device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    max_new_tokens=50,\n",
    "    num_return_sequences=1, \n",
    "    top_k=50, \n",
    "    top_p=0.75, \n",
    "    num_beams=2,\n",
    "    temperature=0.9, \n",
    "    stop_strings=[\"Agent:\", \"User:\", \"\\n\"],\n",
    "    do_sample=True, \n",
    "    tokenizer=tokenizer,\n",
    "    output_attentions=False, \n",
    "    output_logits=True, \n",
    "    return_dict_in_generate=True,\n",
    "    use_cache=False, \n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "Agent: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids, \n",
    "    attention_mask=attn_ids, \n",
    "    **config\n",
    ")\n",
    "\n",
    "output_tokens = output.sequences[:, input_length:].squeeze(0)\n",
    "output_tokens = output_tokens.cpu()       # Move to CPU for decoding if necessary\n",
    "\n",
    "print(tokenizer.decode(output_tokens, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(output.attentions[0]).mean(dim=0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garfield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
